{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from keras.datasets import boston_housing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "X_train = k.utils.normalize(X_train)\n",
    "X_test = k.utils.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.012020</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.600788</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.776719</td>\n",
       "      <td>0.036634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.154587</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.014260</td>\n",
       "      <td>0.029418</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.652077</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.740857</td>\n",
       "      <td>0.005827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.129538</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.862723</td>\n",
       "      <td>0.026167</td>\n",
       "      <td>0.486441</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.013190</td>\n",
       "      <td>0.075376</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.489400</td>\n",
       "      <td>0.044133</td>\n",
       "      <td>0.867155</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.113541</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.855411</td>\n",
       "      <td>0.025945</td>\n",
       "      <td>0.502753</td>\n",
       "      <td>0.018816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.151183</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.583979</td>\n",
       "      <td>0.039882</td>\n",
       "      <td>0.795860</td>\n",
       "      <td>0.023888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.127716</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>0.850586</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.506903</td>\n",
       "      <td>0.030141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.173733</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.700144</td>\n",
       "      <td>0.025539</td>\n",
       "      <td>0.689546</td>\n",
       "      <td>0.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>0.222496</td>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>0.896658</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.376619</td>\n",
       "      <td>0.037046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.166515</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.727669</td>\n",
       "      <td>0.035301</td>\n",
       "      <td>0.660897</td>\n",
       "      <td>0.057298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>0.129437</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.031065</td>\n",
       "      <td>0.862050</td>\n",
       "      <td>0.026146</td>\n",
       "      <td>0.486825</td>\n",
       "      <td>0.026289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.027818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.147884</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.035492</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.029873</td>\n",
       "      <td>0.042576</td>\n",
       "      <td>0.050828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.011066</td>\n",
       "      <td>0.175757</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.587843</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>0.788225</td>\n",
       "      <td>0.029174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.119995</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.031612</td>\n",
       "      <td>0.877240</td>\n",
       "      <td>0.026607</td>\n",
       "      <td>0.461868</td>\n",
       "      <td>0.018691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.228282</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.448922</td>\n",
       "      <td>0.045609</td>\n",
       "      <td>0.857942</td>\n",
       "      <td>0.065094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.108301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.147280</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.035347</td>\n",
       "      <td>0.980887</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>0.024228</td>\n",
       "      <td>0.030369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023209</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.125023</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.030775</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>0.502719</td>\n",
       "      <td>0.003796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.134854</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>0.038722</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.009632</td>\n",
       "      <td>0.689682</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>0.709409</td>\n",
       "      <td>0.009575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.154592</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.071955</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.652097</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.737862</td>\n",
       "      <td>0.013923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.143423</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.689293</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>0.708607</td>\n",
       "      <td>0.016909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.055951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.116919</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.989426</td>\n",
       "      <td>0.030010</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>0.021571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.157565</td>\n",
       "      <td>0.006198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>0.045799</td>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.529417</td>\n",
       "      <td>0.038446</td>\n",
       "      <td>0.831164</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.168217</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>0.013552</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.711824</td>\n",
       "      <td>0.030102</td>\n",
       "      <td>0.680483</td>\n",
       "      <td>0.007880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.035997</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.013149</td>\n",
       "      <td>0.130388</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.591945</td>\n",
       "      <td>0.030597</td>\n",
       "      <td>0.793727</td>\n",
       "      <td>0.009959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.129983</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.044055</td>\n",
       "      <td>0.861052</td>\n",
       "      <td>0.023031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.012549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.126216</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>0.850807</td>\n",
       "      <td>0.025805</td>\n",
       "      <td>0.507035</td>\n",
       "      <td>0.027134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.024593</td>\n",
       "      <td>0.015483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.131029</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.611863</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.778306</td>\n",
       "      <td>0.024455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.131140</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.519409</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.843138</td>\n",
       "      <td>0.008650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.011738</td>\n",
       "      <td>0.182344</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.619929</td>\n",
       "      <td>0.042406</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>0.029906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.130817</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.695909</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>0.704399</td>\n",
       "      <td>0.026875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.174317</td>\n",
       "      <td>0.007008</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>0.565352</td>\n",
       "      <td>0.033593</td>\n",
       "      <td>0.804561</td>\n",
       "      <td>0.019849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.015663</td>\n",
       "      <td>0.131045</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.433076</td>\n",
       "      <td>0.039942</td>\n",
       "      <td>0.890610</td>\n",
       "      <td>0.011309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.137370</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.561119</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.815036</td>\n",
       "      <td>0.018309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.924951</td>\n",
       "      <td>0.028054</td>\n",
       "      <td>0.354467</td>\n",
       "      <td>0.022804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.044986</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.014598</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.520554</td>\n",
       "      <td>0.035989</td>\n",
       "      <td>0.850238</td>\n",
       "      <td>0.011311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>0.052418</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.716919</td>\n",
       "      <td>0.027380</td>\n",
       "      <td>0.689612</td>\n",
       "      <td>0.008214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>0.104917</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>0.604066</td>\n",
       "      <td>0.036562</td>\n",
       "      <td>0.788663</td>\n",
       "      <td>0.011883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.010130</td>\n",
       "      <td>0.159404</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.745020</td>\n",
       "      <td>0.036143</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.028812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.010593</td>\n",
       "      <td>0.164203</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.730718</td>\n",
       "      <td>0.035449</td>\n",
       "      <td>0.659937</td>\n",
       "      <td>0.028359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.162670</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.074422</td>\n",
       "      <td>0.014862</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.668982</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.720447</td>\n",
       "      <td>0.017507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.092391</td>\n",
       "      <td>0.015266</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.670546</td>\n",
       "      <td>0.035813</td>\n",
       "      <td>0.734629</td>\n",
       "      <td>0.020059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.062414</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.576610</td>\n",
       "      <td>0.039681</td>\n",
       "      <td>0.813103</td>\n",
       "      <td>0.020936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.124136</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.855846</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>0.499269</td>\n",
       "      <td>0.021126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.128126</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.690050</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.710859</td>\n",
       "      <td>0.013783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.130395</td>\n",
       "      <td>0.007056</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.557951</td>\n",
       "      <td>0.036783</td>\n",
       "      <td>0.818452</td>\n",
       "      <td>0.011779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.164643</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.732677</td>\n",
       "      <td>0.035544</td>\n",
       "      <td>0.657297</td>\n",
       "      <td>0.035745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.037821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.129905</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.034991</td>\n",
       "      <td>0.971005</td>\n",
       "      <td>0.029451</td>\n",
       "      <td>0.185687</td>\n",
       "      <td>0.038840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.124216</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.582195</td>\n",
       "      <td>0.039093</td>\n",
       "      <td>0.801454</td>\n",
       "      <td>0.030812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.012849</td>\n",
       "      <td>0.058832</td>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.584250</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.807975</td>\n",
       "      <td>0.012520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.008709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.108078</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.030733</td>\n",
       "      <td>0.852846</td>\n",
       "      <td>0.025867</td>\n",
       "      <td>0.508250</td>\n",
       "      <td>0.018824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.011621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023416</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.126009</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.031049</td>\n",
       "      <td>0.861621</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.488679</td>\n",
       "      <td>0.022770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.146467</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.035152</td>\n",
       "      <td>0.975472</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>0.129287</td>\n",
       "      <td>0.054164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.015796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.140318</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.035524</td>\n",
       "      <td>0.985781</td>\n",
       "      <td>0.029899</td>\n",
       "      <td>0.063735</td>\n",
       "      <td>0.035494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.013020</td>\n",
       "      <td>0.108056</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.570121</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.022578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.127598</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.030624</td>\n",
       "      <td>0.849805</td>\n",
       "      <td>0.025775</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.048449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.133288</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.500906</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>0.853261</td>\n",
       "      <td>0.034827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.043808</td>\n",
       "      <td>0.015245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>0.488455</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>0.869363</td>\n",
       "      <td>0.014435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.073644</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.012690</td>\n",
       "      <td>0.049026</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.639647</td>\n",
       "      <td>0.035559</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.016475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.200377</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.010171</td>\n",
       "      <td>0.819818</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>0.532882</td>\n",
       "      <td>0.032121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.128969</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.569615</td>\n",
       "      <td>0.033532</td>\n",
       "      <td>0.809713</td>\n",
       "      <td>0.009415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.002412  0.000000  0.015930  0.000000  0.001053  0.012020  0.179454   \n",
       "1    0.000041  0.154587  0.003804  0.000000  0.000778  0.014260  0.029418   \n",
       "2    0.006345  0.000000  0.023446  0.000000  0.000817  0.006438  0.129538   \n",
       "3    0.000087  0.000000  0.011339  0.000000  0.001125  0.013190  0.075376   \n",
       "4    0.004743  0.000000  0.023248  0.000000  0.000916  0.008189  0.113541   \n",
       "5    0.000578  0.000000  0.015017  0.000000  0.001003  0.011614  0.151183   \n",
       "6    0.011733  0.000000  0.023117  0.000000  0.000894  0.007070  0.127716   \n",
       "7    0.007119  0.000000  0.034017  0.000000  0.001513  0.009500  0.173733   \n",
       "8    0.004795  0.000000  0.043565  0.000000  0.001938  0.012522  0.222496   \n",
       "9    0.002712  0.000000  0.036450  0.000000  0.001039  0.008357  0.166515   \n",
       "10   0.012420  0.000000  0.023428  0.000000  0.000897  0.008289  0.129437   \n",
       "11   0.027818  0.000000  0.026767  0.000000  0.000883  0.006844  0.147884   \n",
       "12   0.000276  0.000000  0.008043  0.000000  0.001013  0.011066  0.175757   \n",
       "13   0.005054  0.000000  0.023841  0.000000  0.001014  0.008234  0.119995   \n",
       "14   0.000925  0.000000  0.061249  0.000000  0.001387  0.013403  0.228282   \n",
       "15   0.108301  0.000000  0.026658  0.000000  0.001000  0.008773  0.147280   \n",
       "16   0.008385  0.000000  0.023209  0.001282  0.000809  0.008996  0.125023   \n",
       "17   0.000125  0.134854  0.004315  0.000000  0.000771  0.012224  0.038722   \n",
       "18   0.000065  0.154592  0.003804  0.000000  0.000778  0.011547  0.071955   \n",
       "19   0.000267  0.000000  0.015365  0.000000  0.000933  0.012075  0.143423   \n",
       "20   0.055951  0.000000  0.026890  0.000000  0.001009  0.009214  0.116919   \n",
       "21   0.000058  0.157565  0.006198  0.000000  0.000899  0.013855  0.045799   \n",
       "22   0.000031  0.168217  0.002603  0.000000  0.000714  0.012634  0.024613   \n",
       "23   0.000013  0.035997  0.004620  0.000000  0.001076  0.013149  0.130388   \n",
       "24   0.000066  0.000000  0.011319  0.000000  0.001123  0.012857  0.129983   \n",
       "25   0.012549  0.000000  0.023123  0.000000  0.000857  0.008679  0.126216   \n",
       "26   0.000174  0.024593  0.015483  0.000000  0.001031  0.011828  0.131029   \n",
       "27   0.000059  0.000000  0.015174  0.000000  0.001007  0.015421  0.131140   \n",
       "28   0.001357  0.000000  0.016437  0.000000  0.001086  0.011738  0.182344   \n",
       "29   0.000317  0.000000  0.017246  0.000000  0.001041  0.009912  0.130817   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "374  0.000144  0.000000  0.028452  0.000000  0.001127  0.013605  0.174317   \n",
       "375  0.000130  0.000000  0.005520  0.000000  0.001095  0.015663  0.131045   \n",
       "376  0.000097  0.000000  0.007087  0.000000  0.001016  0.013336  0.137370   \n",
       "377  0.006683  0.000000  0.025138  0.000000  0.000990  0.009306  0.124993   \n",
       "378  0.000115  0.044986  0.012082  0.000000  0.000940  0.013948  0.045200   \n",
       "379  0.000227  0.081059  0.006196  0.000000  0.000787  0.011809  0.052418   \n",
       "380  0.001571  0.000000  0.019672  0.000000  0.001081  0.012165  0.104917   \n",
       "381  0.000550  0.000000  0.037319  0.000000  0.001064  0.010130  0.159404   \n",
       "382  0.000933  0.000000  0.036603  0.000000  0.001043  0.010593  0.164203   \n",
       "383  0.000095  0.162670  0.003091  0.000000  0.000821  0.014451  0.074422   \n",
       "384  0.000059  0.000000  0.008363  0.000000  0.000842  0.011456  0.092391   \n",
       "385  0.000362  0.000000  0.012318  0.000000  0.001031  0.012330  0.062414   \n",
       "386  0.012754  0.000000  0.023259  0.000000  0.000951  0.008033  0.124136   \n",
       "387  0.000205  0.000000  0.015382  0.000000  0.000934  0.012185  0.128126   \n",
       "388  0.000110  0.000000  0.007047  0.000000  0.001011  0.014629  0.130395   \n",
       "389  0.000419  0.000000  0.036701  0.000000  0.001046  0.009820  0.164643   \n",
       "390  0.037821  0.000000  0.026389  0.000000  0.000990  0.007733  0.129905   \n",
       "391  0.000286  0.000000  0.022258  0.002102  0.001028  0.012745  0.124216   \n",
       "392  0.000618  0.000000  0.015024  0.000000  0.001004  0.012849  0.058832   \n",
       "393  0.008709  0.000000  0.023178  0.000000  0.000913  0.007787  0.108078   \n",
       "394  0.011621  0.000000  0.023416  0.001294  0.000996  0.008037  0.126009   \n",
       "395  0.067003  0.000000  0.026511  0.000000  0.001015  0.006619  0.146467   \n",
       "396  0.015796  0.000000  0.026791  0.000000  0.001095  0.009560  0.140318   \n",
       "397  0.000473  0.000000  0.021796  0.000000  0.001006  0.013020  0.108056   \n",
       "398  0.023603  0.000000  0.023095  0.000000  0.000852  0.005280  0.127598   \n",
       "399  0.000472  0.000000  0.014855  0.000000  0.000963  0.012043  0.133288   \n",
       "400  0.000355  0.043808  0.015245  0.000000  0.001016  0.013668  0.035703   \n",
       "401  0.000073  0.073644  0.012751  0.000000  0.000921  0.012690  0.049026   \n",
       "402  0.004372  0.000000  0.039831  0.000000  0.001772  0.011614  0.200377   \n",
       "403  0.000031  0.128969  0.006298  0.000000  0.000862  0.014195  0.040410   \n",
       "\n",
       "           7         8         9         10        11        12  \n",
       "0    0.007783  0.007828  0.600788  0.041096  0.776719  0.036634  \n",
       "1    0.011749  0.003748  0.652077  0.027545  0.740857  0.005827  \n",
       "2    0.001726  0.031089  0.862723  0.026167  0.486441  0.004223  \n",
       "3    0.013077  0.010924  0.489400  0.044133  0.867155  0.017500  \n",
       "4    0.003297  0.030826  0.855411  0.025945  0.502753  0.018816  \n",
       "5    0.009606  0.010174  0.583979  0.039882  0.795860  0.023888  \n",
       "6    0.002018  0.030652  0.850586  0.025799  0.506903  0.030141  \n",
       "7    0.002453  0.008687  0.700144  0.025539  0.689546  0.045900  \n",
       "8    0.003374  0.011125  0.896658  0.032707  0.376619  0.037046  \n",
       "9    0.002397  0.006661  0.727669  0.035301  0.660897  0.057298  \n",
       "10   0.002121  0.031065  0.862050  0.026146  0.486825  0.026289  \n",
       "11   0.002298  0.035492  0.984906  0.029873  0.042576  0.050828  \n",
       "12   0.005156  0.009930  0.587843  0.032967  0.788225  0.029174  \n",
       "13   0.003024  0.031612  0.877240  0.026607  0.461868  0.018691  \n",
       "14   0.004196  0.004776  0.448922  0.045609  0.857942  0.065094  \n",
       "15   0.002655  0.035347  0.980887  0.029751  0.024228  0.030369  \n",
       "16   0.001542  0.030775  0.854000  0.025902  0.502719  0.003796  \n",
       "17   0.015080  0.009632  0.689682  0.028512  0.709409  0.009575  \n",
       "18   0.011749  0.003748  0.652097  0.027545  0.737862  0.013923  \n",
       "19   0.004986  0.008975  0.689293  0.037516  0.708607  0.016909  \n",
       "20   0.002768  0.035655  0.989426  0.030010  0.027959  0.021571  \n",
       "21   0.011347  0.006303  0.529417  0.038446  0.831164  0.009076  \n",
       "22   0.013552  0.005312  0.711824  0.030102  0.680483  0.007880  \n",
       "23   0.008179  0.002000  0.591945  0.030597  0.793727  0.009959  \n",
       "24   0.012246  0.010905  0.488528  0.044055  0.861052  0.023031  \n",
       "25   0.001735  0.030660  0.850807  0.025805  0.507035  0.027134  \n",
       "26   0.010940  0.009837  0.611863  0.029905  0.778306  0.024455  \n",
       "27   0.010661  0.004293  0.519409  0.038204  0.843138  0.008650  \n",
       "28   0.009454  0.008077  0.619929  0.042406  0.761039  0.029906  \n",
       "29   0.004271  0.010679  0.695909  0.034173  0.704399  0.026875  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "374  0.007008  0.010242  0.565352  0.033593  0.804561  0.019849  \n",
       "375  0.006348  0.006732  0.433076  0.039942  0.890610  0.011309  \n",
       "376  0.006426  0.004156  0.561119  0.036992  0.815036  0.018309  \n",
       "377  0.003607  0.033332  0.924951  0.028054  0.354467  0.022804  \n",
       "378  0.014598  0.008569  0.520554  0.035989  0.850238  0.011311  \n",
       "379  0.008226  0.009007  0.716919  0.027380  0.689612  0.008214  \n",
       "380  0.005246  0.007948  0.604066  0.036562  0.788663  0.011883  \n",
       "381  0.003353  0.006819  0.745020  0.036143  0.644860  0.028812  \n",
       "382  0.003529  0.006688  0.730718  0.035449  0.659937  0.028359  \n",
       "383  0.014862  0.004067  0.668982  0.025621  0.720447  0.017507  \n",
       "384  0.015266  0.005715  0.670546  0.035813  0.734629  0.020059  \n",
       "385  0.007951  0.010334  0.576610  0.039681  0.813103  0.020936  \n",
       "386  0.002825  0.030841  0.855846  0.025958  0.499269  0.021126  \n",
       "387  0.005132  0.008985  0.690050  0.037557  0.710859  0.013783  \n",
       "388  0.007056  0.004133  0.557951  0.036783  0.818452  0.011779  \n",
       "389  0.002798  0.006706  0.732677  0.035544  0.657297  0.035745  \n",
       "390  0.002402  0.034991  0.971005  0.029451  0.185687  0.038840  \n",
       "391  0.008910  0.008407  0.582195  0.039093  0.801454  0.030812  \n",
       "392  0.011025  0.010179  0.584250  0.039900  0.807975  0.012520  \n",
       "393  0.003480  0.030733  0.852846  0.025867  0.508250  0.018824  \n",
       "394  0.002746  0.031049  0.861621  0.026133  0.488679  0.022770  \n",
       "395  0.002429  0.035152  0.975472  0.029586  0.129287  0.054164  \n",
       "396  0.002942  0.035524  0.985781  0.029899  0.063735  0.035494  \n",
       "397  0.008963  0.008233  0.570121  0.038283  0.812722  0.022578  \n",
       "398  0.001451  0.030624  0.849805  0.025775  0.506438  0.048449  \n",
       "399  0.013087  0.006449  0.500906  0.038482  0.853261  0.034827  \n",
       "400  0.009701  0.006571  0.488455  0.040741  0.869363  0.014435  \n",
       "401  0.013973  0.002104  0.639647  0.035559  0.762211  0.016475  \n",
       "402  0.003302  0.010171  0.819818  0.029904  0.532882  0.032121  \n",
       "403  0.013369  0.002149  0.569615  0.033532  0.809713  0.009415  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline\n",
    "housing_model = k.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                168       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 181\n",
      "Trainable params: 181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input => Hidden\n",
    "housing_model.add(k.layers.Dense(12, input_dim=13, activation='relu'))\n",
    "# Output\n",
    "housing_model.add(k.layers.Dense(1))\n",
    "\n",
    "#Compile\n",
    "housing_model.compile(loss='mean_squared_error',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['mse'])\n",
    "\n",
    "housing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = housing_model.fit(X_train,y_train, epochs=100, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 546us/sample - loss: 89.5077 - mse: 89.5077\n",
      "mse: 89.50767517089844\n"
     ]
    }
   ],
   "source": [
    "scores = housing_model.evaluate(X_test, y_test)\n",
    "print(f'{housing_model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1,ax2)) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['loss'], color = 'r')\n",
    "ax1.set_title(\"Loss\")\n",
    "ax2.plot(history.history['mse'], color = 'b')\n",
    "ax2.set_title(\"MSE\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd Iteration\n",
    "housing_model = k.Sequential(name='round2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"round2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 12)                168       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2000)              26000     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 2001      \n",
      "=================================================================\n",
      "Total params: 4,030,169\n",
      "Trainable params: 4,030,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input => Hidden\n",
    "housing_model.add(k.layers.Dense(12, input_dim=13, activation='linear'))\n",
    "# Hidden\n",
    "housing_model.add(k.layers.Dense(2000, activation='relu'))\n",
    "housing_model.add(k.layers.Dense(2000, activation='linear'))\n",
    "\n",
    "# Output\n",
    "housing_model.add(k.layers.Dense(1,activation='linear'))\n",
    "\n",
    "#Compile\n",
    "housing_model.compile(loss='mean_squared_error',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['mse', 'mae'])\n",
    "\n",
    "housing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "history = housing_model.fit(X_train,y_train, epochs=100, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 1ms/sample - loss: 35.3468 - mse: 35.3468 - mae: 4.2250\n",
      "mse: 35.346778869628906\n"
     ]
    }
   ],
   "source": [
    "scores = housing_model.evaluate(X_test, y_test)\n",
    "print(f'{housing_model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1,ax2)) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['mae'], color = 'r')\n",
    "ax1.set_title(\"MAE\")\n",
    "ax2.plot(history.history['mse'], color = 'b')\n",
    "ax2.set_title(\"MSE\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16551\n"
     ]
    }
   ],
   "source": [
    "#Linear Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, preds)\n",
    "print(f'{MSE:.05f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "df[13] = pd.Series(y_train)\n",
    "df1 = pd.DataFrame(X_test)\n",
    "df1[13] = pd.Series(y_test)\n",
    "df = pd.concat([df, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "      <td>42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5      6       7     8      9     10  \\\n",
       "0  1.23247   0.0   8.14  0.0  0.538  6.142   91.7  3.9769   4.0  307.0  21.0   \n",
       "1  0.02177  82.5   2.03  0.0  0.415  7.610   15.7  6.2700   2.0  348.0  14.7   \n",
       "2  4.89822   0.0  18.10  0.0  0.631  4.970  100.0  1.3325  24.0  666.0  20.2   \n",
       "3  0.03961   0.0   5.19  0.0  0.515  6.037   34.5  5.9853   5.0  224.0  20.2   \n",
       "4  3.69311   0.0  18.10  0.0  0.713  6.376   88.4  2.5671  24.0  666.0  20.2   \n",
       "\n",
       "       11     12    13  \n",
       "0  396.90  18.72  15.2  \n",
       "1  395.38   3.11  42.3  \n",
       "2  375.52   3.26  50.0  \n",
       "3  396.90   8.01  21.1  \n",
       "4  391.43  14.65  17.7  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12          13  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "  df[f'{col}_outlier'] = df[col].apply(lambda x: 1 if x > \\\n",
    "                                       np.mean(df[col]) + (np.std(df[col])*2)  # 2 standard deviations away from the mean\n",
    "                                       else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "target = 13\n",
    "omit = [13, '13_outlier']\n",
    "feats = [col for col in df.columns if col not in omit]\n",
    "\n",
    "X = df[feats]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X,y, test_size=.1 ,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = k.utils.normalize(X_train)\n",
    "X_test = k.utils.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.49% improvement\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(f'{((18.16 - mean_squared_error(y_test, y_pred))/18.16)*100:.02f}%\\\n",
    " improvement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"round3...fight\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 13)                351       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               7000      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 258,352\n",
      "Trainable params: 258,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "housing_model = k.Sequential(name='round3...fight')\n",
    "\n",
    "# Input => Hidden\n",
    "housing_model.add(k.layers.Dense(13, input_dim=26, activation='linear'))\n",
    "# Hidden\n",
    "housing_model.add(k.layers.Dense(500, activation='relu'))\n",
    "housing_model.add(k.layers.Dense(500, activation='linear'))\n",
    "\n",
    "# Output\n",
    "housing_model.add(k.layers.Dense(1,activation='linear'))\n",
    "\n",
    "#Compile\n",
    "housing_model.compile(loss='mean_squared_error',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['mse', 'mae'])\n",
    "\n",
    "housing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "history = housing_model.fit(X_train,y_train, epochs=100, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/sample - loss: 14.2684 - mse: 14.2684 - mae: 3.0093\n",
      "mse: 14.26844310760498\n"
     ]
    }
   ],
   "source": [
    "scores = housing_model.evaluate(X_test, y_test)\n",
    "print(f'{housing_model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1,ax2)) = plt.subplots(1,2)\n",
    "ax1.plot(history.history['mae'], color = 'r')\n",
    "ax1.set_title(\"MAE\")\n",
    "ax2.plot(history.history['mse'], color = 'b')\n",
    "ax2.set_title(\"MSE\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.08% improvement\n"
     ]
    }
   ],
   "source": [
    "print(f'{((33.2-17.9)/33.2)*100:.02f}% improvement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Variable Types\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,546\n",
      "Trainable params: 13,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "\n",
    "# Input => Hidden\n",
    "mnist_model.add(Dense(16, input_dim=784, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Hidden\n",
    "mnist_model.add(Dense(16, activation='relu'))\n",
    "# Output\n",
    "mnist_model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "mnist_model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
